{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOrZEV8Qp7VDxd2i8oHlK/G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thiagorainmaker77/BioNLP-Experimentos/blob/master/MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttHEcNsuWjb5"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from sklearn import datasets"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw9UmmUwaLmk",
        "outputId": "617d5766-1881-4537-a6cf-5707e6fea48d"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xf2ImesZWw2d"
      },
      "source": [
        "wine  = datasets.load_wine()\n",
        "data  = wine.data\n",
        "target = wine.target"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8kXr2daW0gY",
        "outputId": "c5c343b3-82b4-4795-9ecf-1cae3a8e46cc"
      },
      "source": [
        "print(data.shape)\n",
        "print(wine.feature_names)\n",
        "print(wine.target_names)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(178, 13)\n",
            "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
            "['class_0' 'class_1' 'class_2']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr23tipSXzJo"
      },
      "source": [
        "class MLPClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, out_size):\n",
        "    super(MLP, self).__init__()\n",
        "    self.hidden = nn.Linear(input_size, hidden_size)\n",
        "    self.relu   = nn.ReLU()\n",
        "    self.out    = nn.Linear(hidden_size, out_size)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, X):\n",
        "    feacture = self.relu(self.hidden(X))\n",
        "    output = self.softmax(self.out(feacture))\n",
        "\n",
        "    return output\n",
        "\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpP6yE0AZ0qC"
      },
      "source": [
        "input_size   = data.shape[1]\n",
        "hidden_size  = 32\n",
        "out_size     = len(wine.target_names)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7T-fNuNaGEv"
      },
      "source": [
        "mlp = MLP(input_size, hidden_size, out_size).to(device)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14Efb_rXbiqx"
      },
      "source": [
        "X = torch.from_numpy(data).float().to(device)\n",
        "Y = torch.from_numpy(target).to(device)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTyWweMxbs4p"
      },
      "source": [
        "pred = mlp(X)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON1WpScebTwa"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXr1S8tUeL7I",
        "outputId": "758494aa-570e-4819-f60f-0678158886b1"
      },
      "source": [
        "loss = criterion(pred, Y)\n",
        "print(loss)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.1526, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvxzZvj6fKxB"
      },
      "source": [
        "#regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkgF50r6fMiu"
      },
      "source": [
        "diabetes = datasets.load_diabetes()\n",
        "data = diabetes.data\n",
        "target = diabetes.target"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IggJwz-f2sG"
      },
      "source": [
        "class MLPRegressor(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, out_size):\n",
        "    super(MLPRegressor, self).__init__()\n",
        "    self.hidden = nn.Linear(input_size, hidden_size)\n",
        "    self.relu   = nn.ReLU()\n",
        "    self.out    = nn.Linear(hidden_size, out_size)\n",
        "    #self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, X):\n",
        "    feacture = self.relu(self.hidden(X))\n",
        "    output = self.out(feacture)\n",
        "    #output = self.softmax(self.out(feacture))\n",
        "\n",
        "    return output"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZCm3nZrf9mI"
      },
      "source": [
        "input_size   = data.shape[1]\n",
        "hidden_size  = 32\n",
        "out_size     = 1"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfR0OHrag6TL"
      },
      "source": [
        "X = torch.from_numpy(data).float().to(device)\n",
        "Y = torch.from_numpy(target).float().to(device)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S62eiQr6hhjR"
      },
      "source": [
        "mlp_regressor = MLPRegressor(input_size, hidden_size, out_size).to(device)\n",
        "pred = mlp_regressor(X)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6335o0zgb3C",
        "outputId": "f070782c-692a-453f-cbac-a10aea0d6762"
      },
      "source": [
        "criterion = nn.MSELoss().to(device)\n",
        "loss = criterion(pred.squeeze(), Y)\n",
        "print(loss)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(28771.2168, device='cuda:0', grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}